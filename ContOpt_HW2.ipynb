{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Optimisation HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "data = loadmat('data-toy.mat')\n",
    "print(data.keys())\n",
    "print(data['K'])\n",
    "sigma = float(data['sigma'])\n",
    "\n",
    "'''\n",
    "K = data['K']\n",
    "P = data['P']\n",
    "X0 = data['X0']\n",
    "d = data['d']\n",
    "delta_0 = data['delta_0']\n",
    "delta_bar = data['delta_bar']\n",
    "n = data['n']\n",
    "sigma = data['sigma']\n",
    "y = data['y']\n",
    "'''\n",
    "\n",
    "sigmasquared = sigma**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Implement phi(x, P), bigphi(X, P), f(X, P, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "#TODO Vectorise all the functions\n",
    "\n",
    "def h(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Gaussian filter\n",
    "\n",
    "    :x: np.ndarray[(1, 2)]\n",
    "    :returns: float\n",
    "    \"\"\"\n",
    "    return np.e**(-np.inner(x, x)/sigmasquared)  # Always take sigma = 0.1\n",
    "\n",
    "\n",
    "def phi(x,P):\n",
    "    \"\"\"\n",
    "    Calculate contribution of each 'true' star to observed image\n",
    "    \n",
    "    :x: np.ndarray[(2, 1)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(n**2, 1)]\n",
    "    \"\"\"\n",
    "    # print(f\"P is {P}\")\n",
    "    # print(f\"x is {x}\")\n",
    "    # print(f\"P-x is {P-x}\")\n",
    "    # print(h(P - x).reshape(-1, 1))\n",
    "    # print((np.e**((-1/sigmasquared)*np.sum((P.T-x.T)**2,axis=1))).reshape(-1, 1))\n",
    "    # return h(P - x).reshape(-1, 1)\n",
    "    return (np.e**((-1/sigmasquared)*np.sum((P.T-x.T)**2,axis=1))).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def bigphi(X, P):\n",
    "    \"\"\"\n",
    "    Calculate image observed, based on K-star positions X\n",
    "    \n",
    "    :X: np.ndarray[(2, K)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(n**2, 1)]\n",
    "    \"\"\"\n",
    "    global K, n\n",
    "    #non-vectorised code just in case we need it\n",
    "    bigphi = np.zeros((n**2, 1))\n",
    "    for i in range(K):\n",
    "         bigphi += phi(X[2*i:2*i+2], P)\n",
    "    #return phi(X, P)\n",
    "    return bigphi\n",
    "\n",
    "\n",
    "def  f(X, P, y):\n",
    "    \"\"\"\n",
    "    Calculate squared error of estimate bigphi(X)\n",
    "    \n",
    "    :X: np.ndarray[(2, K)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :y: np.ndarray[(n**2, 1)]\n",
    "    :returns: float\n",
    "    \"\"\"\n",
    "    global K, n\n",
    "    return (1/(2*n**2)) * np.linalg.norm(bigphi(X, P)-y)**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that $f$ is not convex. There are clear local maxima which cannot occur if $f$ were convex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "n = 2\n",
    "true_positions = np.array([[0], [0]])\n",
    "positions = np.array([[0.5, 0.5], [-0.5, 0.5], [-0.5, -0.5], [0.5, -0.5]]).T\n",
    "y = np.array([[0], [0], [1], [0]])\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x_vals = np.linspace(-1, 1, 100)\n",
    "y_vals = np.linspace(-1, 1, 100)\n",
    "x_vals, y_vals = np.meshgrid(x_vals, y_vals)\n",
    "grid = np.array([x_vals, y_vals]).reshape((2, 100**2))\n",
    "z_vals = np.zeros((1, 10000))\n",
    "for i in range(10000):\n",
    "    z_vals[0, i] = f(grid[:, i].reshape((2, 1)), positions, y)\n",
    "z_vals = z_vals.reshape((100, 100))\n",
    "ax.scatter(x_vals, y_vals, z_vals)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_phi_i_0(x,p_i):\n",
    "    \"\"\"\n",
    "    Computes value of cell i_0 of jacobian of phi\n",
    "    \n",
    "    :x: np.ndarray[(2, 1)]\n",
    "    :p_i: np.ndarray[(2, 1)]\n",
    "    :returns: float\n",
    "    \"\"\"\n",
    "    return (2/sigmasquared)*(p_i[0]-x[0])*np.e**((-1/sigmasquared)*np.inner(p_i-x,p_i-x))\n",
    "\n",
    "def d_phi_i_1(x,p_i):\n",
    "    \"\"\"\n",
    "    Computes value of cell i_1 of jacobian of phi\n",
    "    \n",
    "    :x: np.ndarray[(2, 1)]\n",
    "    :p_i: np.ndarray[(2, 1)]\n",
    "    :returns: float\n",
    "    \"\"\"\n",
    "    return (2/sigmasquared)*(p_i[1]-x[1])*np.e**((-1/sigmasquared)*np.inner(p_i-x,p_i-x))\n",
    "    \n",
    "def d_phi(x, P):\n",
    "    \"\"\"\n",
    "    Computes the jacobian of small phi\n",
    "\n",
    "    :x: np.ndarray[(1, 2)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(n**2, 2)]\n",
    "    \"\"\"\n",
    "    # Subtract x from each column of P\n",
    "    diff = P.T - x\n",
    "    # Compute the squared differences\n",
    "    squared_diff = np.sum(diff**2, axis=1)\n",
    "    # Compute the exponential term for all elements at once\n",
    "    exp_term = np.exp((-1 / sigmasquared) * squared_diff)\n",
    "    # Compute the values for d_phi_i_0 and d_phi_i_1 using vectorized operations\n",
    "    d_phi_0 = (2 / sigmasquared) * diff[:, 0] * exp_term\n",
    "    d_phi_1 = (2 / sigmasquared) * diff[:, 1] * exp_term\n",
    "    # Stack the results to form the final array\n",
    "    d_phi = np.stack((d_phi_0, d_phi_1), axis=1)\n",
    "    return d_phi\n",
    "\n",
    "def d_big_phi(X,P):\n",
    "    \"\"\"\n",
    "    Computes the jacobian of big phi\n",
    "\n",
    "    :X: np.ndarray[(1, 2K)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(n**2, 2K)]\n",
    "    \"\"\"\n",
    "    d_big_phi = np.zeros((n**2,2*K))\n",
    "    for i in range(K):\n",
    "        d_big_phi[0:n**2,2*i:2*i+2] = d_phi(X[2*i:2*i+2].T,P)\n",
    "    return d_big_phi\n",
    "\n",
    "def d_f(X,P):\n",
    "    \"\"\"\n",
    "    Computes the jacobian of f\n",
    "\n",
    "    :X: np.ndarray[(1, 2K)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(1, 2K)]\n",
    "    \"\"\"\n",
    "    return (1/n**2)*(bigphi(X,P)-y).T@d_big_phi(X,P)\n",
    "\n",
    "#compute gradient of f\n",
    "def grad_f(X,P):\n",
    "    \"\"\"\n",
    "    Computes the gradient of f\n",
    "\n",
    "    :X: np.ndarray[(1, 2K)]\n",
    "    :P: np.ndarray[(2, n**2)]\n",
    "    :returns: np.ndarray[(2K, 1)]\n",
    "    \"\"\"\n",
    "    return d_f(X,P).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking gradient is correct numerically\n",
    "K = int(data['K'])\n",
    "P = data['P']\n",
    "X0 = data['X0']\n",
    "d = int(data['d'])\n",
    "delta_0 = data['delta_0']\n",
    "delta_bar = data['delta_bar']\n",
    "n = int(data['n'])\n",
    "sigma = float(data['sigma'])\n",
    "y = data['y'].flatten(order='F').reshape(n**2,1)\n",
    "\n",
    "#check that the gradient is correct using\n",
    "# f(x+tv)= f(x) + t<v,grad_f(x)> + O(t^2)\n",
    "\n",
    "# Generate a random point and a random direction\n",
    "theta = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)\n",
    "v = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)\n",
    "v = v / np.linalg.norm(v)\n",
    "\n",
    "## Check the gradient \n",
    "def checkgradient(f,grad_f, theta,v):\n",
    "    #logspace of t values\n",
    "    t=np.logspace(-8, 0, num=100)\n",
    "    #intialise error to 0\n",
    "    error = np.zeros_like(t)\n",
    "    #pre-calculae f_lambda and f_lambda_grad to use in for loop\n",
    "    f_lambda = f(theta,P,y)\n",
    "    f_lambda_grad = grad_f(theta,P)\n",
    "    #compute the error at each t\n",
    "    for i in tqdm(range(100)):\n",
    "        error[i] = np.abs( f(theta+(t[i]*v),P,y)-f_lambda-(t[i]*v.T@f_lambda_grad) )\n",
    "        \n",
    "    #plot the graph of error vs t\n",
    "    plt.loglog(t,error)\n",
    "    plt.xlabel('t (log scale)')\n",
    "    plt.ylabel('Error (log scale)')\n",
    "    plt.title('Plot of t vs Error')\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "checkgradient(f,grad_f,theta,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "## Computing the Hessian \n",
    "\n",
    "First we re-derive the gradient of f:\n",
    "\n",
    "$$ f(x) = \\frac{1}{2n^2}||\\Phi(x) - y ||^2$$\n",
    "\n",
    "$$ Df(x)[v] = \\frac{1}{n^2}< \\Phi(x) - y,D \\Phi(x)[v] > = \\frac{1}{n^2}<(D\\Phi(x))^*[\\Phi(x) - y],v> $$\n",
    "\n",
    "$$ \\nabla f(x) = \\frac{(D\\Phi(x))^*[\\Phi(x) - y]}{n^2} $$\n",
    "\n",
    "Then, using the above calculations, we can calculate the hessian:\n",
    "\n",
    "$$ \\frac{1}{n^2}[D((D\\Phi(x))^*[\\Phi(x) - y])[v]] = \\frac{1}{n^2}[D((D\\Phi(x))^*[v])[\\Phi(x) - y] + (D\\Phi(x))^*[D\\Phi(x)[v]]]$$\n",
    "\n",
    "\n",
    "$$ \\nabla^2 f(x)[v] = \\frac{1}{n^2}[(D(D\\Phi(x))^*[v])[\\Phi(x)-y]+D\\Phi(x)^*[D\\Phi(x)[v]]] $$\n",
    "\n",
    "The implicit reason why we are calculating the hessian with respect to a direction v is because it is computationally much cheaper than to calculate the full hessian which means calculating all 2nd order partial derivatives of f.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_g(x,p,v):\n",
    "    \"\"\"\n",
    "    Computes directional derivative of g_1, g_2 at x in the direction v\n",
    "\n",
    "    :param x: np.ndarray[(2, 1)] \"position of a stat\"\n",
    "    :param p: np.ndarray[(2, 1)] \"pixel positions\"\n",
    "    :param v: np.ndarray[(2, 1)] \"vector direction of change in star position\"\n",
    "    :returns: scalar\n",
    "    \"\"\"\n",
    "    d_g_1 = np.zeros((1,2))\n",
    "    d_g_1[0][0] = ((4/sigmasquared**2)*((p[0]-x[0])**2)*np.e**(-(p-x).T@(p-x)/sigmasquared))-(2/sigmasquared)*np.e**(-(p-x).T@(p-x)/sigmasquared)\n",
    "    d_g_1[0][1] = (4/sigmasquared**2)*(p[0]-x[0])*(p[1]-x[1])*np.e**(-(p-x).T@(p-x)/sigmasquared)\n",
    "\n",
    "    d_g_2 = np.zeros((1,2))\n",
    "    d_g_2[0][0] = d_g_1[0][1]\n",
    "    d_g_2[0][1] = ((4/sigmasquared**2)*((p[1]-x[1])**2)*np.e**(-(p-x).T@(p-x)/sigmasquared))-(2/sigmasquared)*np.e**(-(p-x).T@(p-x)/sigmasquared)\n",
    "\n",
    "    return d_g_1@v,d_g_2@v\n",
    "\n",
    "\n",
    "def d_d_phi(X, P, V):\n",
    "    \"\"\"\n",
    "    Compute the directional derivative of the Jacobian of phi at x in the direction v.\n",
    "\n",
    "    :param X: np.ndarray[(1, 2K)] \"position of a stat\"\n",
    "    :param P: np.ndarray[(2, n**2)] \"pixel positions\"\n",
    "    :param V: np.ndarray[(1, 2K)] \"vector direction of change in star position\"\n",
    "    :returns: np.ndarray[(n**2, 2K)]\n",
    "    \"\"\"\n",
    "    d_d_phi = np.zeros((n**2,2*K))\n",
    "    for i in range(K):\n",
    "        for j in range(n**2):\n",
    "            #puts p_j in an array\n",
    "            p_j = np.array(\n",
    "                [\n",
    "                 [P[0][j]],\n",
    "                 [P[1][j]]\n",
    "                 ]\n",
    "                );\n",
    "            d_d_phi[j,2*i],d_d_phi[j,2*i+1] = d_g(X[2*i:2*i+2],p_j,V[2*i:2*i+2])\n",
    "    return d_d_phi\n",
    "    \n",
    "\n",
    "\n",
    "def hessian_f(X,V):\n",
    "    \"\"\"\n",
    "    Compute the Hessian of f at X in the direction v.\n",
    "    \n",
    "    :param X: np.ndarray[(2, K)] \"position of K stars\"\n",
    "    :param P: np.ndarray[(2, n**2)] \"pixel positions\"\n",
    "    :param y: np.ndarray[(n**2, 1)] \"actual image detected, y = \\Phi(X_true)\" remember we want to find X_true\n",
    "    :param v: np.ndarray[(2, K)] \"direction at which hessian is taken\" \n",
    "    :returns: np.ndarray[(2*K, 1)]\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute intermediate terms\n",
    "    phi_X = bigphi(X, P) - y  # (n**2, 1)\n",
    "    d_big_phi_X = d_big_phi(X, P)  # (n**2, 2*K)\n",
    "    d_big_phi_X_v = d_big_phi(X, P) @ V  # directional derivative of big_phi in direction v\n",
    "\n",
    "    # Compute each term in the Hessian formula\n",
    "\n",
    "    term1 = d_d_phi(X, P, V).T @ phi_X \n",
    "    term2 = d_big_phi_X.T @ d_big_phi_X_v \n",
    "\n",
    "    hessian = (1 / n**2) * (term1 + term2)\n",
    "    return hessian\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_random = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)  # Random X\n",
    "U_random = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)  # Random direction U\n",
    "U_random /= np.linalg.norm(U_random)  # Normalize U\n",
    "\n",
    "#check that the gradient is correct using\n",
    "# f(x+tv)= f(x) + t<v,grad_f(x)> + t^2/2*v.T@hess_f(x)[v] + O(t^3)\n",
    "\n",
    "# Generate a random point and a random direction\n",
    "theta = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)\n",
    "v = np.random.uniform(-0.5, 0.5, (d, K)).flatten(order='F').reshape(d*K,1)\n",
    "v = v / np.linalg.norm(v)\n",
    "\n",
    "## Check the hessian \n",
    "def checkhessian(f,grad_f,hessian_f,theta,v):\n",
    "    #logspace of t values\n",
    "    t=np.logspace(-8, 0, num=100)\n",
    "    #intialise error to 0\n",
    "    error = np.zeros_like(t)\n",
    "    #pre-calculae f_lambda and f_lambda_grad to use in for loop\n",
    "    f_lambda = f(theta,P,y)\n",
    "    f_lambda_grad = grad_f(theta,P)\n",
    "    f_lambda_hess_v = hessian_f(theta,v)\n",
    "    print(f_lambda_hess_v.shape)\n",
    "    #compute the error at each t\n",
    "    for i in tqdm(range(100)):\n",
    "        error[i] = np.abs(f(theta+(t[i]*v),P,y)-f_lambda-(t[i]*v.T@f_lambda_grad)- ((t[i]**2)/2)*v.T@f_lambda_hess_v)\n",
    "        \n",
    "    #plot the graph of error vs t\n",
    "    plt.loglog(t,error)\n",
    "    plt.xlabel('t (log scale)')\n",
    "    plt.ylabel('Error (log scale)')\n",
    "    plt.title('Plot of t vs Error')\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "checkhessian(f,grad_f,hessian_f,theta,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tCG(H: np.ndarray, b: np.array, radius: float) -> tuple:\n",
    "    v0, r0, p0 = 0, b, b  # Here, when there is a \"0\" after the variable, it means it's the \"iterated\" variable ie it changes on every loop\n",
    "    while True:\n",
    "        Hp = H @ p0\n",
    "        inner = np.inner(p0, Hp)\n",
    "        alpha = np.inner(r0, r0)/inner\n",
    "        v_plus = v0 + alpha * p0\n",
    "        if inner <= 0 or np.linalg.norm(v_plus) >= radius:\n",
    "            inner_pv = np.inner(v0, p0)\n",
    "            norm2_p = np.inner(p0, p0)\n",
    "            t = (-inner_pv + np.sqrt(inner_pv - (np.inner(v0, v0) - radius**2) * norm2_p))/norm2_p\n",
    "            v0 += t * p0\n",
    "            return (v0, b - r0 + t*Hp, True)  # since we solved ||v0|| = Delta, the flag is true\n",
    "        else:\n",
    "            v0 = v_plus\n",
    "        r_old = r0\n",
    "        r0 -= alpha * Hp\n",
    "        if np.norm(r0) <= np.norm(b) * min(np.norm(r0), 0.1):\n",
    "            return (v0, b - r0, False)  # flag is false\n",
    "        beta0 = np.inner(r0, r0)/np.inner(r_old, r_old)\n",
    "        p0 = r0 + beta0 * p0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRsolver(x0: np.array, Delta0: float, DeltaBar: float, rhoPrime: float=0.1) -> np.array:\n",
    "    TRsub = tCG(hessian_f())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
